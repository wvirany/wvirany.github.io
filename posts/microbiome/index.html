<!DOCTYPE html>
<html lang="en-us"
  dir="ltr">

  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width">



<link rel="icon" type="image/ico" href="http://localhost:1313//favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313//favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313//favicon-32x32.png">
<link rel="icon" type="image/png" sizes="192x192" href="http://localhost:1313//android-chrome-192x192.png">
<link rel="apple-touch-icon" sizes="180x180" href="http://localhost:1313//apple-touch-icon.png">

<meta name="description" content=""/>

<title>
    
    Predicting Microbiome-Phenotype Associations in the Human Gut | Walter Virany
    
</title>

<link rel="canonical" href="http://localhost:1313/posts/microbiome/"/>












<link rel="stylesheet" href="/assets/combined.min.c5b19f349890ba8c8308e8d948f1754211fca49303531d62bb79927877c7df0e.css" media="all">





  </head>

  

  
  
  

  <body class="light">

    <div class="content">
      <header>
        

<div class="header">

    

    <h1 class="header-title">Walter Virany</h1>
    
    
    

    <div class="flex">
        

        
        
      
        <p class="small ">
            <a href="/" >
                /blog
            </a>
        </p>
        
      
        <p class="small ">
            <a href="/me" >
                /me
            </a>
        </p>
        
      
        <p class="small ">
            <a href="/why" >
                /why?
            </a>
        </p>
        
        
    </div>

    

</div>

      </header>

      <main class="main">
        







<div >

  <div class="single-intro-container">

    

    <h1 class="single-title">Predicting Microbiome-Phenotype Associations in the Human Gut</h1>
    

    

    <p class="single-readtime">
      
      
      
      <time datetime="2023-12-14T00:00:00&#43;00:00">December 14, 2023</time>
      

      
      &nbsp; Â· &nbsp;
      16 min read
      
    </p>

  </div>

  

  

  

  

  <div class="single-content">
    <p>The human microbiome is a data rich ecosystem, which is generally known to have strong associations with host phenotypes (i.e., the set of observable characteristics of an organism). Yet, the extents of these relationships are not yet deeply understood. Until recently, the computing capabilities necessary to thoroughly analyze human microbiome data were severely lacking. However, due to novel advancements in sequencing technologies and data analysis techniques, there now exist a plethora of data, along with robust statistical tools, which can be leveraged to gain valuable insights into the impact of the human microbiome on overall health. Methods which can accurately detect disease early in developmental stages have the potential to revolutionize personalized and preventative medicine.</p>
<p>In this post, I explore state-of-the-art machine learning methods for processing human microbiome data, building upon the work of <a href="https://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.1004977&amp;type=printable">Pasolli et al. [2016]</a>. Using data from the <a href="https://pubmed.ncbi.nlm.nih.gov/31142855/">Integrative Human Microbiome Project (HMP2) [2019]</a>, I demonstrate that IBD can be accurately identified using just 20 species of bacteria found in the human gut - a dramatic reduction from previous approaches requiring 200+ features. My majority-vote classification approach, an ensemble of XGBoost, CatBoost, LightGBM and random forests, achieves an ROC AUC score of 0.945 - a notable improvement from the previous study&rsquo;s 0.890.</p>
<h2 id="data-loading-and-preprocessing">Data Loading and Preprocessing</h2>
<p>The data I will be analyzing was taken as part of the <a href="https://pubmed.ncbi.nlm.nih.gov/31142855/">Integrative Human Microbiome Project (HMP2) [2019]</a>, which includes 1627 stool samples from clinical patients. Each patient was classified with IBD or as a control (i.e., healthy) - this is the target variable. The features are the relative species abundances found in each stool sample. This is the proportion of each species recorded in the sample with respect to the others.</p>
<p>I&rsquo;m accessing data from <code>curatedMetagenomicData()</code>, a package within the R Bioconductor library which grants accessed to the dataset curated by <a href="https://www.biorxiv.org/content/10.1101/103085v2.full.pdf">Pasolli et al. [2017]</a>.</p>
<p>First, I&rsquo;ll load the necessary packages and configure some settings:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#00f">import</span> numpy <span style="color:#00f">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#00f">import</span> pandas <span style="color:#00f">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#00f">import</span> matplotlib.pyplot <span style="color:#00f">as</span> plt
</span></span><span style="display:flex;"><span><span style="color:#00f">import</span> seaborn <span style="color:#00f">as</span> sns
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00f">from</span> sklearn.preprocessing <span style="color:#00f">import</span> MinMaxScaler
</span></span><span style="display:flex;"><span><span style="color:#00f">from</span> sklearn.pipeline <span style="color:#00f">import</span> Pipeline
</span></span><span style="display:flex;"><span><span style="color:#00f">from</span> sklearn.metrics <span style="color:#00f">import</span> roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score, confusion_matrix, RocCurveDisplay
</span></span><span style="display:flex;"><span><span style="color:#00f">from</span> sklearn.linear_model <span style="color:#00f">import</span> LassoCV, ElasticNetCV
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00f">from</span> sklearn.svm <span style="color:#00f">import</span> SVC
</span></span><span style="display:flex;"><span><span style="color:#00f">from</span> sklearn.ensemble <span style="color:#00f">import</span> RandomForestClassifier, VotingClassifier
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00f">from</span> xgboost <span style="color:#00f">import</span> XGBClassifier
</span></span><span style="display:flex;"><span><span style="color:#00f">from</span> lightgbm <span style="color:#00f">import</span> LGBMClassifier
</span></span><span style="display:flex;"><span><span style="color:#00f">from</span> catboost <span style="color:#00f">import</span> CatBoostClassifier
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00f">import</span> warnings
</span></span><span style="display:flex;"><span>warnings.filterwarnings(<span style="color:#a31515">&#34;ignore&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>np.random.seed(1984)
</span></span></code></pre></div><p>Next, I load the data as a pandas dataframe, explore the structure of the data, and perform some transformations:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>ibd = pd.read_csv(<span style="color:#a31515">&#34;data/ibd_rel_abundance.csv&#34;</span>)
</span></span><span style="display:flex;"><span>healthy = pd.read_csv(<span style="color:#a31515">&#34;data/healthy_rel_abundance.csv&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(ibd.shape())
</span></span></code></pre></div><p>We see that there are 1201 samples with IBD, each with 579 features describing the relative species abundances.</p>
<pre tabindex="0"><code>ibd.head()
</code></pre><div>
<style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }
</style>
    <table border="1" class="dataframe">
    <thead>
        <tr style="text-align: right;">
        <th></th>
        <th>Phocaeicola vulgatus</th>
        <th>Bacteroides uniformis</th>
        <th>Bacteroides thetaiotaomicron</th>
        <th>Faecalibacterium prausnitzii</th>
        <th>Roseburia faecis</th>
        <th>Bacteroides caccae</th>
        <th>Enterocloster clostridioformis</th>
        <th>Bacteroides fragilis</th>
        <th>Fusicatenibacter saccharivorans</th>
        <th>Flavonifractor plautii</th>
        <th>...</th>
        <th>Prevotella histicola</th>
        <th>Prevotella pallens</th>
        <th>Chlamydia ibidis</th>
        <th>Enterococcus mundtii</th>
        <th>Anaerostipes sp. 992a</th>
        <th>Actinobaculum sp. oral taxon 183</th>
        <th>Lachnoclostridium sp. An298</th>
        <th>Haemophilus haemolyticus</th>
        <th>Enterococcus dispar</th>
        <th>Atopobium minutum</th>
        </tr>
    </thead>
    <tbody>
        <tr>
        <th>0</th>
        <td>8436640</td>
        <td>6235541</td>
        <td>1357098</td>
        <td>1054351</td>
        <td>999360</td>
        <td>551484</td>
        <td>334448</td>
        <td>168192</td>
        <td>139201</td>
        <td>133264</td>
        <td>...</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        </tr>
        <tr>
        <th>1</th>
        <td>17080974</td>
        <td>9468596</td>
        <td>2861845</td>
        <td>189087</td>
        <td>190713</td>
        <td>479440</td>
        <td>315591</td>
        <td>182143</td>
        <td>268493</td>
        <td>427323</td>
        <td>...</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        </tr>
        <tr>
        <th>2</th>
        <td>12088033</td>
        <td>14919763</td>
        <td>7543241</td>
        <td>452106</td>
        <td>455094</td>
        <td>1991901</td>
        <td>537137</td>
        <td>7969977</td>
        <td>5346</td>
        <td>185637</td>
        <td>...</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        </tr>
        <tr>
        <th>3</th>
        <td>9174317</td>
        <td>15253970</td>
        <td>4019070</td>
        <td>988736</td>
        <td>429513</td>
        <td>964149</td>
        <td>46820</td>
        <td>3271311</td>
        <td>37552</td>
        <td>86170</td>
        <td>...</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        </tr>
        <tr>
        <th>4</th>
        <td>3662205</td>
        <td>8560295</td>
        <td>7882055</td>
        <td>817546</td>
        <td>814911</td>
        <td>686063</td>
        <td>27640</td>
        <td>4984518</td>
        <td>9446</td>
        <td>411733</td>
        <td>...</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        <td>0</td>
        </tr>
    </tbody>
    </table>
</div>
<p>Here we see the first five rows of the pandas dataframe containing the relative species abundances for the IBD samples. We can plot the relative abundances for a few samples to get a sense for the dataset.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#008000"># Histogram of the first 3 elements of the healthy dataframe</span>
</span></span><span style="display:flex;"><span>healthy[:3].plot(kind=<span style="color:#a31515">&#39;bar&#39;</span>, legend=<span style="color:#00f">False</span>, logy=<span style="color:#00f">True</span>, xlabel=<span style="color:#a31515">&#39;Species in Healthy samples&#39;</span>, ylabel=<span style="color:#a31515">&#39;Log scale of relative abundances&#39;</span>, rot=0);
</span></span></code></pre></div><div id="fig1" class="figure">
  <img src="figures/healthy_unscaled.png" alt="Unscaled Healthy" style="width:70%; margin-left: auto; margin-right:auto">
</div>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#008000"># Histogram of the first 3 elements of the IBD dataframe</span>
</span></span><span style="display:flex;"><span>ibd[:3].plot(kind=<span style="color:#a31515">&#39;bar&#39;</span>, legend=<span style="color:#00f">False</span>, logy=<span style="color:#00f">True</span>, xlabel=<span style="color:#a31515">&#39;Species in IBD samples&#39;</span>, ylabel=<span style="color:#a31515">&#39;Log scale of relative abundances&#39;</span>, rot=0);
</span></span></code></pre></div><div id="fig2" class="figure">
  <img src="figures/ibd_unscaled.png" alt="Unscaled IBD" style="width:70%; margin-left: auto; margin-right:auto">
</div>
<p>Immediately, we notice that the healthy samples seem to have higher biodiversity. We can also see that the scale of the entries varies drastically. Of the nonzero features, the scales differ from $\sim 10^3$ to $\sim 10^7$. It&rsquo;s a similar story for the healthy samples. To address this, we will incorporate min-max scaling into our pipeline later.</p>
<p>This is unlabeled data, so we need to insert the target variable:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>healthy.insert(0, <span style="color:#a31515">&#39;IBD&#39;</span>, 0); <span style="color:#008000"># 0 for control sample</span>
</span></span><span style="display:flex;"><span>ibd.insert(0, <span style="color:#a31515">&#39;IBD&#39;</span>, 1); <span style="color:#008000"># 1 for case sample</span>
</span></span></code></pre></div><p>Now, to construct our full dataset, I concatenate the two and shuffle them. I also rename some of the columns to remove characters that will prove problematic later when training our models.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#008000"># Concatenate, shuffle, and reindex</span>
</span></span><span style="display:flex;"><span>data = pd.concat([ibd, healthy]).sample(frac=1).set_index(np.arange(0, 1627))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#008000"># Replace brackets in column names</span>
</span></span><span style="display:flex;"><span>data.columns = data.columns.str.replace(<span style="color:#a31515">&#39;[&#39;</span>, <span style="color:#a31515">&#39;&#39;</span>).str.replace(<span style="color:#a31515">&#39;]&#39;</span>, <span style="color:#a31515">&#39;&#39;</span>)
</span></span></code></pre></div><p>Finally, I construct the train, validation, and test sets using an 80/10/10 split:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#008000"># Create partitions at 80% and 90% of original dataset, resulting in three subsets</span>
</span></span><span style="display:flex;"><span>train, val, test = np.split(data.sample(frac=1), [int(.8*len(data)), int(.9*len(data))])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_train = train.drop(<span style="color:#a31515">&#39;IBD&#39;</span>, axis=1).fillna(0) <span style="color:#008000"># Features</span>
</span></span><span style="display:flex;"><span>y_train = train[<span style="color:#a31515">&#39;IBD&#39;</span>] <span style="color:#008000"># Targets</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_val = val.drop(<span style="color:#a31515">&#39;IBD&#39;</span>, axis=1).fillna(0)
</span></span><span style="display:flex;"><span>y_val = val[<span style="color:#a31515">&#39;IBD&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_test = test.drop(<span style="color:#a31515">&#39;IBD&#39;</span>, axis=1).fillna(0)
</span></span><span style="display:flex;"><span>y_test = test[<span style="color:#a31515">&#39;IBD&#39;</span>]
</span></span></code></pre></div><h2 id="feature-selection-w-lasso-and-elasticnet">Feature Selection w/ LASSO and ElasticNet</h2>
<p>The resulting dataset is a high-dimensional sparse matrix containing relative species abundances. My goal is to narrow down this set of features to see which are the most important in predicting the target variable. In the long run, this will help us make biological insights into which species are most commonly linked to IBD.</p>
<p>First, I implement a baseline SVM classifier with min-max scaling:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>steps = [
</span></span><span style="display:flex;"><span>    (<span style="color:#a31515">&#39;scaler&#39;</span>, MinMaxScaler()),  <span style="color:#008000"># Data preprocessing step</span>
</span></span><span style="display:flex;"><span>    (<span style="color:#a31515">&#39;classifier&#39;</span>, SVC(C=2048, gamma=.5, kernel=<span style="color:#a31515">&#39;rbf&#39;</span>, random_state=1))  <span style="color:#008000"># Model step</span>
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>svm_base = Pipeline(steps)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>svm_base.fit(X_train, y_train)
</span></span></code></pre></div><p>To evaluate this model, we can visualize the ROC curve:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>fig, ax = plt.subplots(figsize=(8, 6))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>fig_params = {<span style="color:#a31515">&#39;estimator&#39;</span> : pipeline,
</span></span><span style="display:flex;"><span>              <span style="color:#a31515">&#39;name&#39;</span> : <span style="color:#a31515">&#39;Base SVM&#39;</span>,
</span></span><span style="display:flex;"><span>              <span style="color:#a31515">&#39;X&#39;</span> : X_test,
</span></span><span style="display:flex;"><span>              <span style="color:#a31515">&#39;y&#39;</span> : y_test,
</span></span><span style="display:flex;"><span>              <span style="color:#a31515">&#39;ax&#39;</span> : ax,
</span></span><span style="display:flex;"><span>              <span style="color:#a31515">&#39;c&#39;</span> : <span style="color:#a31515">&#39;black&#39;</span>,
</span></span><span style="display:flex;"><span>              <span style="color:#a31515">&#39;ls&#39;</span> : <span style="color:#a31515">&#39;dashed&#39;</span>,
</span></span><span style="display:flex;"><span>              <span style="color:#a31515">&#39;lw&#39;</span> : 1}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>RocCurveDisplay.from_estimator(**fig_params)
</span></span><span style="display:flex;"><span>ax.plot([0,1], c=<span style="color:#a31515">&#39;gray&#39;</span>, ls=<span style="color:#a31515">&#39;dotted&#39;</span>, lw=.75)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ax.set_title(<span style="color:#a31515">&#39;ROC Curve&#39;</span>)
</span></span><span style="display:flex;"><span>ax.set_xlabel(<span style="color:#a31515">&#39;False Positive Rate&#39;</span>)
</span></span><span style="display:flex;"><span>ax.set_ylabel(<span style="color:#a31515">&#39;True Positive Rate&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt.show();
</span></span></code></pre></div><div id="fig3" class="figure">
  <img src="figures/roc_svm_base.png" alt="SVM Base ROC" style="width:75%; margin-left: auto; margin-right:auto">
</div>
<p>We see that the base SVM estimator achieves an ROC AUC score of 0.89. Now, I want to perform feature selection on the dataset and see how the model performs on various subsets of the original features. So, I implement two different feature selection methods: Lasso and Elastic Net Regularization. Then, I assess each model&rsquo;s accuracy on different subsets of the features.</p>
<p>First, I implement <code>LassoCV()</code>, which searches for the optimal <code>alpha</code> parameter in $\{10^{-4}, 10^{-3.5}, \dots, 10^{.5}\}$, as described in <a href="https://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.1004977&amp;type=printable">Pasolli et al. [2016]</a>:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>alphas = [10**(x) <span style="color:#00f">for</span> x <span style="color:#00f">in</span> np.arange(-4, 0, step=.5)]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>lassoCV = LassoCV(cv = 5,
</span></span><span style="display:flex;"><span>                  alphas=alphas,
</span></span><span style="display:flex;"><span>                  random_state=42).fit(X_train, y_train)
</span></span></code></pre></div><p>Similarly, I implement <code>ENetCV()</code>, which searches for the optimal <code>alpha</code> parameter as before, as well as the optimal <code>l1_ratio</code> parameter in $\{.1, .5, .7, .9, .95, .99, 1\}$:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>l1_ratios = [.1, .5, .7, .9, .95, .99, 1]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>enetCV = ElasticNetCV(l1_ratio=l1_ratios,
</span></span><span style="display:flex;"><span>                      alphas=alphas,
</span></span><span style="display:flex;"><span>                      cv=5,
</span></span><span style="display:flex;"><span>                      random_state=1984).fit(X_train, y_train)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>enetCV.l1_ratio_
</span></span></code></pre></div><pre tabindex="0"><code>Output: 1.0
</code></pre><p>Interestingly, ENetCV returned an <code>l1_ratio</code> value of 1.0, completely favoring an $L^1$-norm. In this case, ElasticNet is equivalent to LASSO, so I&rsquo;ll only use LASSO hereafter.</p>
<p>Next, I remove all of the columns in which the lasso coefficient is zero:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>X_lasso = data.drop([<span style="color:#a31515">&#39;IBD&#39;</span>], axis=1).copy()
</span></span><span style="display:flex;"><span>coefs = lassoCV.coef_.copy()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00f">while</span>(int(np.min(np.abs(coefs)) == 0)):
</span></span><span style="display:flex;"><span>    idx = np.argmin(np.abs(coefs))
</span></span><span style="display:flex;"><span>    X_lasso = X_lasso.drop(X_lasso.columns[idx], axis=1)
</span></span><span style="display:flex;"><span>    coefs = np.delete(coefs, idx)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>X_lasso.shape
</span></span></code></pre></div><pre tabindex="0"><code>Output: (1627, 444)
</code></pre><p>I&rsquo;ll also create train, validation, and test splits for this reduced dataset:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>X_train_lasso = X_train[X_lasso.columns]
</span></span><span style="display:flex;"><span>X_val_lasso = X_val[X_lasso.columns]
</span></span><span style="display:flex;"><span>X_test_lasso = X_test[X_lasso.columns]
</span></span></code></pre></div><p>Now we see that the number of features has been reduced to 444, from the original 579. Moreover, the lasso coefficients now specify relative importances for each feature. I want to further reduce the number features, so I will train and validate the model while varying the percentage of features included in the process, each time selecting the top-$p$ proportion of the features, where $p \in [0, 1]$. This will tell us if a model is still capable of making accurate predictions on even smaller subsets of the features.</p>
<p>In code, this looks like the following:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#008000"># Redefine `steps` to incorporate randomness into the model</span>
</span></span><span style="display:flex;"><span>steps = [
</span></span><span style="display:flex;"><span>    (<span style="color:#a31515">&#39;scaler&#39;</span>, MinMaxScaler()),  <span style="color:#008000"># Data preprocessing step</span>
</span></span><span style="display:flex;"><span>    (<span style="color:#a31515">&#39;classifier&#39;</span>, SVC(C=2048, gamma=.5, kernel=<span style="color:#a31515">&#39;rbf&#39;</span>))  <span style="color:#008000"># Model step</span>
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>percentiles = [.1 * x <span style="color:#00f">for</span> x <span style="color:#00f">in</span> np.arange(10)]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>total_coefs = coefs.size
</span></span><span style="display:flex;"><span>svm_scores = np.zeros(len(percentiles))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00f">for</span> i, percent <span style="color:#00f">in</span> enumerate(percentiles):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    columns = []
</span></span><span style="display:flex;"><span>    lasso_coefs = coefs.copy()
</span></span><span style="display:flex;"><span>    d = X_lasso.copy()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#008000"># Contructing the dataset with top p percent of features included:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00f">for</span> _ <span style="color:#00f">in</span> range(int((1-percent) * total_coefs)):
</span></span><span style="display:flex;"><span>        <span style="color:#008000"># Get index of most important feature, append to columns</span>
</span></span><span style="display:flex;"><span>        idx = np.argmax(np.abs(lasso_coefs))
</span></span><span style="display:flex;"><span>        columns.append(d.columns[idx])
</span></span><span style="display:flex;"><span>        <span style="color:#008000"># Remove feature from list to search for next most important feature</span>
</span></span><span style="display:flex;"><span>        lasso_coefs = np.delete(lasso_coefs, idx)
</span></span><span style="display:flex;"><span>        d.drop(d.columns[idx], axis=1, inplace=<span style="color:#00f">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#008000"># Construct train and validation sets on new subset of features</span>
</span></span><span style="display:flex;"><span>    train = X_train_lasso[columns]
</span></span><span style="display:flex;"><span>    val = X_val_lasso[columns]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#008000"># Training / testing and averaging results:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00f">for</span> _ <span style="color:#00f">in</span> range(20):
</span></span><span style="display:flex;"><span>        svm = Pipeline(steps)
</span></span><span style="display:flex;"><span>        svm.fit(train, y_train)
</span></span><span style="display:flex;"><span>        svm_scores[i] += roc_auc_score(y_val, svm.decision_function(val)) / 20
</span></span></code></pre></div><p>We can also visualize these scores:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>fig, ax = plt.subplots(figsize=(6, 4))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ticks = [0.0, 0.2, 0.4, 0.6, 0.8]
</span></span><span style="display:flex;"><span>labels = [<span style="color:#a31515">&#39;0.1 / 44&#39;</span>, <span style="color:#a31515">&#39;0.3 / 133&#39;</span>, <span style="color:#a31515">&#39;0.5 / 222&#39;</span>, <span style="color:#a31515">&#39;0.7 / 310&#39;</span>, <span style="color:#a31515">&#39;0.9 / 399&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ax.plot(percentiles[::-1], svm_scores, label=<span style="color:#a31515">&#39;Lasso Features&#39;</span>, c=<span style="color:#a31515">&#39;midnightblue&#39;</span>, lw=.75)
</span></span><span style="display:flex;"><span>ax.set_xlabel(<span style="color:#a31515">&#39;Proportion / Number of Features Included&#39;</span>)
</span></span><span style="display:flex;"><span>ax.set_xticks(ticks, labels)
</span></span><span style="display:flex;"><span>ax.set_ylabel(<span style="color:#a31515">&#39;ROC AUC Score&#39;</span>)
</span></span><span style="display:flex;"><span>ax.set_title(<span style="color:#a31515">&#39;ROC AUC scores vs. proportion of features for SVM&#39;</span>);
</span></span></code></pre></div><div id="fig4" class="figure">
  <img src="figures/varying_feature_proportions.png" alt="Varying Feature Proportions" style="width:80%; margin-left: auto; margin-right:auto">
</div>
<p>We see that with even just 30% of the nonzero LASSO predictors included, the SVM model is able to achieve a decent ROC AUC score - around 0.8. Recall, this 30% corresponds to 133 of the original 579 features - we are slowly whittling down the dimensionality of our dataset.</p>
<p>So, we&rsquo;ll make a reduced dataset with the top 30% of features:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>columns = []
</span></span><span style="display:flex;"><span>lasso_coefs = coefs.copy()
</span></span><span style="display:flex;"><span>d = X_lasso.copy()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00f">for</span> _ <span style="color:#00f">in</span> range(int(.2 * total_coefs)):
</span></span><span style="display:flex;"><span>    idx = np.argmax(np.abs(lasso_coefs))
</span></span><span style="display:flex;"><span>    columns.append(d.columns[idx])
</span></span><span style="display:flex;"><span>    lasso_coefs = np.delete(lasso_coefs, idx)
</span></span><span style="display:flex;"><span>    d.drop(d.columns[idx], axis=1, inplace=<span style="color:#00f">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>train30 = X_train_lasso[columns]
</span></span><span style="display:flex;"><span>val30 = X_val_lasso[columns]
</span></span><span style="display:flex;"><span>test30 = X_test_lasso[columns]
</span></span></code></pre></div><p>Now, I&rsquo;ll train an SVM on this reduced dataset, and see how it performs in comparison to the baseline estimator.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>steps = [
</span></span><span style="display:flex;"><span>    (<span style="color:#a31515">&#39;scaler&#39;</span>, MinMaxScaler()),  <span style="color:#008000"># Data preprocessing step</span>
</span></span><span style="display:flex;"><span>    (<span style="color:#a31515">&#39;classifier&#39;</span>, SVC(C=2048, gamma=.5, kernel=<span style="color:#a31515">&#39;rbf&#39;</span>, random_state=1984))  <span style="color:#008000"># Model step</span>
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>svm_lasso = Pipeline(steps)
</span></span><span style="display:flex;"><span>svm_lasso.fit(train30, y_train)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>fig, ax = plt.subplots(figsize=(8, 6))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>fig_params1 = {<span style="color:#a31515">&#39;estimator&#39;</span> : svm_base,
</span></span><span style="display:flex;"><span>              <span style="color:#a31515">&#39;name&#39;</span> : <span style="color:#a31515">&#39;Base SVM&#39;</span>,
</span></span><span style="display:flex;"><span>              <span style="color:#a31515">&#39;X&#39;</span> : X_val,
</span></span><span style="display:flex;"><span>              <span style="color:#a31515">&#39;y&#39;</span> : y_val,
</span></span><span style="display:flex;"><span>              <span style="color:#a31515">&#39;ax&#39;</span> : ax,
</span></span><span style="display:flex;"><span>              <span style="color:#a31515">&#39;c&#39;</span> : <span style="color:#a31515">&#39;black&#39;</span>,
</span></span><span style="display:flex;"><span>              <span style="color:#a31515">&#39;ls&#39;</span> : <span style="color:#a31515">&#39;dashed&#39;</span>,
</span></span><span style="display:flex;"><span>              <span style="color:#a31515">&#39;lw&#39;</span> : 1}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>fig_params2 = {<span style="color:#a31515">&#39;estimator&#39;</span> : svm_lasso,
</span></span><span style="display:flex;"><span>              <span style="color:#a31515">&#39;name&#39;</span> : <span style="color:#a31515">&#39;Lasso SVM&#39;</span>,
</span></span><span style="display:flex;"><span>              <span style="color:#a31515">&#39;X&#39;</span> : val30,
</span></span><span style="display:flex;"><span>              <span style="color:#a31515">&#39;y&#39;</span> : y_val,
</span></span><span style="display:flex;"><span>              <span style="color:#a31515">&#39;ax&#39;</span> : ax,
</span></span><span style="display:flex;"><span>              <span style="color:#a31515">&#39;c&#39;</span> : <span style="color:#a31515">&#39;darkorange&#39;</span>,
</span></span><span style="display:flex;"><span>              <span style="color:#a31515">&#39;ls&#39;</span> : <span style="color:#a31515">&#39;solid&#39;</span>,
</span></span><span style="display:flex;"><span>              <span style="color:#a31515">&#39;lw&#39;</span> : 1}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>RocCurveDisplay.from_estimator(**fig_params1)
</span></span><span style="display:flex;"><span>RocCurveDisplay.from_estimator(**fig_params2)
</span></span><span style="display:flex;"><span>ax.plot([0,1], c=<span style="color:#a31515">&#39;gray&#39;</span>, ls=<span style="color:#a31515">&#39;dotted&#39;</span>, lw=.75)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ax.set_title(<span style="color:#a31515">&#39;ROC Curves for SVM Estimators&#39;</span>)
</span></span><span style="display:flex;"><span>ax.set_xlabel(<span style="color:#a31515">&#39;False Positive Rate&#39;</span>)
</span></span><span style="display:flex;"><span>ax.set_ylabel(<span style="color:#a31515">&#39;True Positive Rate&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt.show();
</span></span></code></pre></div><div id="fig5" class="figure">
  <img src="figures/roc_svm_lasso.png" alt="SVM LASSO ROC" style="width:75%; margin-left: auto; margin-right:auto">
</div>
<p>As we can see, the SVM trained on this reduced dataset still achieves good predictability - the ROC AUC score fell by approximately 10%, but this is a small decrease considering that we reduced the dimensionality of the feature space from 579 to 133 - almost an 80% decrease.</p>
<h2 id="improving-the-predictability">Improving the Predictability</h2>
<p>Here comes the fun part: let&rsquo;s see how high of a score we can achieve with more sophisticated models. I&rsquo;ll start by constructing a random forest and comparing it&rsquo;s accuracy to the SVM. The process for constructing the RF is outlined in <a href="https://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.1004977&amp;type=printable">Pasolli et al. [2016]</a>, which I reiterate here:</p>
<ul>
<li>
<p>The parameters are chosen as</p>
<ul>
<li>
<p>Number of trees: 500</p>
</li>
<li>
<p>Criterion: Gini impurity</p>
</li>
<li>
<p>Number of features considered at each split: $m = \sqrt{p}$, where $p$ is the total number of predictors</p>
</li>
<li>
<p><code>class_weight = balanced</code>, to account for the imabalance between # of case samples vs. controls (i.e., there are more patients with IBD in the dataset than healthy patients)</p>
</li>
</ul>
</li>
<li>
<p><code>GridSearchCV()</code> is performed in an attempt to achieve more optimal parameters; however, no significant improvements were made, so the original parameters were kept</p>
</li>
<li>
<p>An implicit feature selection is performed using the impurity-based feature importance. The steps for this process are:</p>
<ol>
<li>The RF is trained on the whole dataset</li>
<li>The features were ranked according to the impurity-based importance</li>
<li>The RF is retrained on the top $k$ features, where $k$ is chosen from $\{5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 125, 150, 175, 200\}$</li>
<li>The number of features that maximizes the accuracy is chosen</li>
<li>The final model is retrained on this subset of features</li>
</ol>
</li>
</ul>
<p>I&rsquo;ll start by training the initial RF:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>rf = RandomForestClassifier(n_estimators=500,
</span></span><span style="display:flex;"><span>                           criterion=<span style="color:#a31515">&#39;gini&#39;</span>,
</span></span><span style="display:flex;"><span>                           max_features=<span style="color:#a31515">&#39;sqrt&#39;</span>,
</span></span><span style="display:flex;"><span>                           class_weight=<span style="color:#a31515">&#39;balanced&#39;</span>,
</span></span><span style="display:flex;"><span>                           random_state=1984).fit(X_train, y_train)
</span></span></code></pre></div><p>During the training process for RFs, an implicit feature importance is assigned to each predictor based on the gini impurity. Based on these feature importances, we select the top-$k$ features, selecting a different value for $k$ each time. We re-evaluate an RF on each of these subsets of size $k$, ultimately choosing the value for $k$ which results in the best performance. This is implemented as follows:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>feature_importances = rf.feature_importances_
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>num_features = [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 125, 150, 175, 200]
</span></span><span style="display:flex;"><span>rf_scores = []
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00f">for</span> k <span style="color:#00f">in</span> num_features:
</span></span><span style="display:flex;"><span>    K_train = X_train.copy()
</span></span><span style="display:flex;"><span>    K_val = X_val.copy()
</span></span><span style="display:flex;"><span>    features = feature_importances
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#008000"># Constructing list of top k features by dropping lowest 579 - k features:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00f">for</span> i <span style="color:#00f">in</span> range(579 - k):
</span></span><span style="display:flex;"><span>        idx = np.argmin(features)
</span></span><span style="display:flex;"><span>        K_train = K_train.drop(K_train.columns[idx], axis=1)
</span></span><span style="display:flex;"><span>        features = np.delete(features, idx)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    rf_temp = RandomForestClassifier(n_estimators=500,
</span></span><span style="display:flex;"><span>                                     criterion=<span style="color:#a31515">&#39;gini&#39;</span>,
</span></span><span style="display:flex;"><span>                                     max_features=<span style="color:#a31515">&#39;sqrt&#39;</span>,
</span></span><span style="display:flex;"><span>                                     class_weight=<span style="color:#a31515">&#39;balanced&#39;</span>,
</span></span><span style="display:flex;"><span>                                     random_state=1984).fit(K_train, y_train)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    K_val = K_val[K_train.columns]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    rf_scores.append(rf_temp.score(K_val, y_val))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>k = num_features[np.argmax(rf_scores)]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#a31515">f</span><span style="color:#a31515">&#34;k = </span><span style="color:#a31515">{</span>k<span style="color:#a31515">}</span><span style="color:#a31515">&#34;</span>)
</span></span></code></pre></div><pre tabindex="0"><code>Output: k = 200
</code></pre><p>We see that the optimal value for $k$ is 200. So, we&rsquo;ll construct a dataset from the top 200 features, then re-train an RF:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>features = feature_importances
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>K_train = X_train.copy()
</span></span><span style="display:flex;"><span>K_val = X_val.copy()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00f">for</span> i <span style="color:#00f">in</span> range(579 - k):
</span></span><span style="display:flex;"><span>    idx = np.argmin(features)
</span></span><span style="display:flex;"><span>    K_train = K_train.drop(K_train.columns[idx], axis=1)
</span></span><span style="display:flex;"><span>    features = np.delete(features, idx)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>K_val = K_val[K_train.columns]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>rf = RandomForestClassifier(n_estimators=500,
</span></span><span style="display:flex;"><span>                            criterion=<span style="color:#a31515">&#39;gini&#39;</span>,
</span></span><span style="display:flex;"><span>                            max_features=<span style="color:#a31515">&#39;sqrt&#39;</span>,
</span></span><span style="display:flex;"><span>                            class_weight=<span style="color:#a31515">&#39;balanced&#39;</span>,
</span></span><span style="display:flex;"><span>                            random_state=1984).fit(K_train, y_train)
</span></span></code></pre></div><p>Once again, we&rsquo;ll visualize the ROC curve for the RF, and compare it to the two SVM models:</p>
<div id="fig6" class="figure">
  <img src="figures/roc_RF.png" alt="Random Forest ROC" style="width:75%; margin-left: auto; margin-right:auto">
</div>
<p>It appears that the RF model is much more powerful - trained on 200 features, it vastly outperforms both models, even the baseline SVM trained on all 579 features.
It can also be informative to visualize the confusion matrices for each model, detailing the true/false positive/negative rates for each category.</p>
<div id="fig7" class="figure">
  <img src="figures/confusion_matrices_three_models.png" alt="Three Confusion Matrices" style="width:100%; margin-left: auto; margin-right:auto">
</div>
<p>Interestingly, it appears that all three models classify the healthy samples with higher precision than unhealthy samples.
The random forest even achieves a perfect classification rate for healthy samples.
It&rsquo;s important to note here the imbalance between the two classes, which we accounted for by setting the <code>class_weight</code> parameter equal to <code>balanced</code> for the RF model.
This adjusts the weights according to the class frequencies, assigning higher weight to classes with less examples.</p>
<p>Finally, I&rsquo;ll build a large ensemble model to see how much predictive performance we can achieve.
I&rsquo;ll follow a similar process for selecting features as before, successively training different classifiers on subsets of the features of varying size (up to 200).
I use the same feature importances retrieved from the RF model trained on the entire feature space.
Then, I select the subset of features for which the model achieved the best performance - this results in a $k$ value of 100.
The classifier will be a voting classifier consisting of several models: XGBoost, LightGBM, CatBoost, and RF. This involves training each constituent model, then taking a majority vote during inference.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#008000"># Setting model parameters</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>lgbm = LGBMClassifier(**{  <span style="color:#a31515">&#39;objective&#39;</span>           : <span style="color:#a31515">&#39;binary&#39;</span>,
</span></span><span style="display:flex;"><span>                           <span style="color:#a31515">&#39;boosting_type&#39;</span>       : <span style="color:#a31515">&#39;gbdt&#39;</span>,
</span></span><span style="display:flex;"><span>                           <span style="color:#a31515">&#39;metric&#39;</span>              : <span style="color:#a31515">&#34;auc&#34;</span>,
</span></span><span style="display:flex;"><span>                           <span style="color:#a31515">&#39;random_state&#39;</span>        : 42,
</span></span><span style="display:flex;"><span>                           <span style="color:#a31515">&#39;colsample_bytree&#39;</span>    : 0.56,
</span></span><span style="display:flex;"><span>                           <span style="color:#a31515">&#39;subsample&#39;</span>           : 0.35,
</span></span><span style="display:flex;"><span>                           <span style="color:#a31515">&#39;learning_rate&#39;</span>       : 0.05,
</span></span><span style="display:flex;"><span>                           <span style="color:#a31515">&#39;max_depth&#39;</span>           : 8,
</span></span><span style="display:flex;"><span>                           <span style="color:#a31515">&#39;n_estimators&#39;</span>        : 1000,
</span></span><span style="display:flex;"><span>                           <span style="color:#a31515">&#39;num_leaves&#39;</span>          : 140,
</span></span><span style="display:flex;"><span>                           <span style="color:#a31515">&#39;reg_alpha&#39;</span>           : 0.14,
</span></span><span style="display:flex;"><span>                           <span style="color:#a31515">&#39;reg_lambda&#39;</span>          : 0.85,
</span></span><span style="display:flex;"><span>                           <span style="color:#a31515">&#39;verbosity&#39;</span>           : -1,
</span></span><span style="display:flex;"><span>                          })
</span></span><span style="display:flex;"><span>xgb  = XGBClassifier(**{  <span style="color:#a31515">&#39;objective&#39;</span>             : <span style="color:#a31515">&#39;binary:logistic&#39;</span>,
</span></span><span style="display:flex;"><span>                          <span style="color:#a31515">&#39;eval_metric&#39;</span>           : <span style="color:#a31515">&#34;auc&#34;</span>,
</span></span><span style="display:flex;"><span>                          <span style="color:#a31515">&#39;random_state&#39;</span>          : 42,
</span></span><span style="display:flex;"><span>                          <span style="color:#a31515">&#39;colsample_bytree&#39;</span>      : 0.25,
</span></span><span style="display:flex;"><span>                          <span style="color:#a31515">&#39;learning_rate&#39;</span>         : 0.07,
</span></span><span style="display:flex;"><span>                          <span style="color:#a31515">&#39;max_depth&#39;</span>             : 8,
</span></span><span style="display:flex;"><span>                          <span style="color:#a31515">&#39;n_estimators&#39;</span>          : 800,
</span></span><span style="display:flex;"><span>                          <span style="color:#a31515">&#39;reg_alpha&#39;</span>             : 0.09,
</span></span><span style="display:flex;"><span>                          <span style="color:#a31515">&#39;reg_lambda&#39;</span>            : 0.70,
</span></span><span style="display:flex;"><span>                          <span style="color:#a31515">&#39;min_child_weight&#39;</span>      : 22,
</span></span><span style="display:flex;"><span>                          <span style="color:#a31515">&#39;verbosity&#39;</span>             : 0,
</span></span><span style="display:flex;"><span>                         })
</span></span><span style="display:flex;"><span>cat  = CatBoostClassifier(**{
</span></span><span style="display:flex;"><span>                         <span style="color:#a31515">&#39;iterations&#39;</span>            : 10000,
</span></span><span style="display:flex;"><span>                         <span style="color:#a31515">&#39;objective&#39;</span>             : <span style="color:#a31515">&#39;Logloss&#39;</span>,
</span></span><span style="display:flex;"><span>                         <span style="color:#a31515">&#39;eval_metric&#39;</span>           : <span style="color:#a31515">&#34;AUC&#34;</span>,
</span></span><span style="display:flex;"><span>                         <span style="color:#a31515">&#39;early_stopping_rounds&#39;</span> : 1000,
</span></span><span style="display:flex;"><span>                         <span style="color:#a31515">&#39;bagging_temperature&#39;</span>   : 0.1,
</span></span><span style="display:flex;"><span>                         <span style="color:#a31515">&#39;colsample_bylevel&#39;</span>     : 0.88,
</span></span><span style="display:flex;"><span>                         <span style="color:#a31515">&#39;iterations&#39;</span>            : 1000,
</span></span><span style="display:flex;"><span>                         <span style="color:#a31515">&#39;learning_rate&#39;</span>         : 0.065,
</span></span><span style="display:flex;"><span>                         <span style="color:#a31515">&#39;max_depth&#39;</span>             : 7,
</span></span><span style="display:flex;"><span>                         <span style="color:#a31515">&#39;l2_leaf_reg&#39;</span>           : 1,
</span></span><span style="display:flex;"><span>                         <span style="color:#a31515">&#39;min_data_in_leaf&#39;</span>      : 25,
</span></span><span style="display:flex;"><span>                         <span style="color:#a31515">&#39;random_strength&#39;</span>       : 0.1,
</span></span><span style="display:flex;"><span>                         <span style="color:#a31515">&#39;max_bin&#39;</span>               : 100,
</span></span><span style="display:flex;"><span>                         <span style="color:#a31515">&#39;verbose&#39;</span>               : 0,
</span></span><span style="display:flex;"><span>                        })
</span></span><span style="display:flex;"><span>rf_vote = RandomForestClassifier(**{<span style="color:#a31515">&#39;n_estimators&#39;</span> : 500,
</span></span><span style="display:flex;"><span>                               <span style="color:#a31515">&#39;criterion&#39;</span>    : <span style="color:#a31515">&#39;gini&#39;</span>,
</span></span><span style="display:flex;"><span>                               <span style="color:#a31515">&#39;max_features&#39;</span> : <span style="color:#a31515">&#39;sqrt&#39;</span>,
</span></span><span style="display:flex;"><span>                               <span style="color:#a31515">&#39;class_weight&#39;</span> : <span style="color:#a31515">&#39;balanced&#39;</span>,
</span></span><span style="display:flex;"><span>                               <span style="color:#a31515">&#39;random_state&#39;</span> : 1984
</span></span><span style="display:flex;"><span>                            })
</span></span></code></pre></div><p>Next, I&rsquo;m going to train two instances of this classifier: one trained on the top 100 features, and one trained on the top 20 features.</p>
<p>The pipeline for each of the classifiers is defined as follows:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#008000"># Pipeline for model trained on top k features</span>
</span></span><span style="display:flex;"><span>vote = VotingClassifier(
</span></span><span style="display:flex;"><span>    estimators=[(<span style="color:#a31515">&#39;lgbm&#39;</span>, lgbm), (<span style="color:#a31515">&#39;xgb&#39;</span>, xgb), (<span style="color:#a31515">&#39;cat&#39;</span>, cat), (<span style="color:#a31515">&#39;rf&#39;</span>, rf_vote)],
</span></span><span style="display:flex;"><span>    voting=<span style="color:#a31515">&#39;soft&#39;</span>,
</span></span><span style="display:flex;"><span>    weights = [2, 1, 1, .5]
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>steps = [
</span></span><span style="display:flex;"><span>    (<span style="color:#a31515">&#39;scaler&#39;</span>, MinMaxScaler()),  <span style="color:#008000"># Data preprocessing step</span>
</span></span><span style="display:flex;"><span>    (<span style="color:#a31515">&#39;model&#39;</span>, vote)  <span style="color:#008000"># Model step</span>
</span></span><span style="display:flex;"><span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#008000"># Pipeline for model trained on 20 features</span>
</span></span><span style="display:flex;"><span>vote_20 = VotingClassifier(
</span></span><span style="display:flex;"><span>    estimators=[(<span style="color:#a31515">&#39;lgbm&#39;</span>, lgbm), (<span style="color:#a31515">&#39;xgb&#39;</span>, xgb), (<span style="color:#a31515">&#39;cat&#39;</span>, cat), (<span style="color:#a31515">&#39;rf&#39;</span>, rf_vote)],
</span></span><span style="display:flex;"><span>    voting=<span style="color:#a31515">&#39;soft&#39;</span>,
</span></span><span style="display:flex;"><span>    weights = [2, 1, 1, .5]
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>steps_20 = [
</span></span><span style="display:flex;"><span>    (<span style="color:#a31515">&#39;scaler&#39;</span>, MinMaxScaler()),  <span style="color:#008000"># Data preprocessing step</span>
</span></span><span style="display:flex;"><span>    (<span style="color:#a31515">&#39;model&#39;</span>, vote_20)  <span style="color:#008000"># Model step</span>
</span></span><span style="display:flex;"><span>]
</span></span></code></pre></div><p>I construct the two corresponding datasets as before, one with 100 features, one with 20. The ROC curve for each model is shown:</p>
<div id="fig8" class="figure">
  <img src="figures/roc_voting_classifier.png" alt="Voting Classifier ROC" style="width:75%; margin-left: auto; margin-right:auto">
</div>
<p>The ROC curve shows comparable performance between the two models, with slightly better prediction rates for the voting classifier trained on 100 features - half as many as the RF.
Moreover, the voting classifier trained on only <em>20 features</em> achieves an ROC AUC score of .96 - that&rsquo;s impressive considering the large reduction in feature space. This could be very important in terms of identifying biomarkers for IBD.</p>
<h2 id="results">Results</h2>
<p>Finally, I summarize the results for each of the models, assessing various classification metrics on the test set. I also include a summary of the original study&rsquo;s best results, each result reported for their model which achieved the highest score for that metric.</p>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ROC AUC</th>
      <th>Accuracy</th>
      <th>Balanced Accuracy</th>
      <th>Precision</th>
      <th>F1 Score</th>
      <th>Recall</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>RF (200 features)</th>
      <td>0.955</td>
      <td>0.957</td>
      <td>0.934</td>
      <td>0.95</td>
      <td>0.97</td>
      <td>0.991</td>
    </tr>
    <tr>
      <th>Voting Classifier (100 features)</th>
      <td>0.958</td>
      <td>0.963</td>
      <td>0.945</td>
      <td>0.958</td>
      <td>0.974</td>
      <td>0.991</td>
    </tr>
    <tr>
      <th>Voting Classifier (20 features)</th>
      <td>0.945</td>
      <td>0.926</td>
      <td>0.895</td>
      <td>0.925</td>
      <td>0.949</td>
      <td>0.974</td>
    </tr>
    <tr>
      <th>Original Study</th>
      <td>0.89</td>
      <td>0.78</td>
      <td>-</td>
      <td>0.78</td>
      <td>0.78</td>
      <td>0.81</td>
    </tr>
  </tbody>
</table>
</div>
<p>Even when using just 20 features (about 3.5% of the original feature set), the voting classifier maintains strong performance with an ROC AUC score of 0.945 and F1 score of 0.949. This suggests that a very small subset of bacterial species may be sufficient for accurate IBD diagnosis.</p>
<p>It is important to note here that the original study had a slightly different experimental setup. These results which they report were from cross-validated test scores evaluated on data taken in different studies. This is slightly different to my experimental setup, where I took several datasets from different studies and shuffled them together, training and testing on samples across datasets.a</p>
<h2 id="discussion">Discussion</h2>
<p>In this post, I used machine learning techniques to predict disease presence in patients from gut microbiome samples, building upon the work of <a href="https://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.1004977&amp;type=printable">Pasolli et al. [2016]</a>. By leveraging a larger dataset, implementing modern ensemble methods (XGBoost, CatBoost, and LightGBM), and implementing feature selection techniques, I was able to improve upon their prediction accuracy. The highest ROC AUC score we achieved was 0.98, on just 100 of the original 579 features. Moreover, I was able to achieve an ROC AUC score of 0.96 with a subset of just 20 features, identifying potential biological markers for early diagnosis.</p>
<p>In future work, it would be interesting to ultimately increase the scale of this project, which can be done in a number of ways:</p>
<ul>
<li>Generalizing results to larger datasets</li>
<li>Performing analysis on different diseases</li>
<li>Performing cross-validation of results across different studies (i.e., different sets of microbiome samples)</li>
</ul>
<p>Additionally, it would be interesting to explore how the differences in the selected features vary for each algorithm (e.g., LASSO, ENet, RF, etc.) It would also be informative to further investigate which samples are being misclassified.</p>
<p>All the code in this post can be found at <a href="https://github.com/wvirany/microbiome">https://github.com/wvirany/microbiome</a>.</p>
<h2 id="references">References</h2>
<ol>
<li>
<p>Edoardo Pasolli, Duy Tin Truong, Faizan Malik, Levi Waldron, and Nicola Segata. Machine learning meta-analysis of
large metagenomic datasets: Tools and biological insights. PLoS Comput. Biol., 12(7):e1004977, July 2016.</p>
</li>
<li>
<p>Lloyd-Price, J., Arze, C., Ananthakrishnan, A.N. et al. Multi-omics of the gut microbial ecosystem in inflammatory bowel diseases. Nature 569, 655â662 (2019). doi.org/10.1038/s41586-019-1237-9.</p>
</li>
<li>
<p>Pasolli E, Schiffer L, Manghi P, Renson A, Obenchain V, Truong D, Beghini F, Malik F, Ramos M, Dowd J, Huttenhower C, Morgan M, Segata N, Waldron L (2017). âAccessible, curated metagenomic data through ExperimentHub.â Nat. Methods, 14(11), 1023â1024. ISSN 1548-7091, 1548-7105, doi:10.1038/nmeth.4468.</p>
</li>
</ol>

    
  </div>

  

  

  

  
  <div class="back-to-top">
    <a href="#top">
      back to top
    </a>
  </div>
  

</div>


      </main>
    </div>

    <footer>
      
<link rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css">
<script defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js"></script>

<script defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js"
  onload="renderMathInElement(document.body);"></script>

<script>
  document.addEventListener("DOMContentLoaded", function () {
    renderMathInElement(document.body, {
      delimiters: [
        { left: "$$", right: "$$", display: true },
        { left: "$", right: "$", display: false }
      ],
      macros: {
        "\\R": "\\mathbb{R}",
        "\\C": "\\mathbb{C}",
        "\\Z": "\\mathbb{Z}",
        "\\N": "\\mathbb{N}",
        "\\Q": "\\mathbb{Q}",
        "\\EE": "\\mathbb{E}",
        "\\x": "\\mathbf{x}",
        "\\X": "\\mathbf{X}",
        "\\y": "\\mathbf{y}",
        "\\z": "\\mathbf{z}",
        "\\u": "\\mathbf{u}",
        "\\U": "\\mathbf{U}",
        "\\I": "\\mathbf{I}",
        "\\A": "\\mathbf{A}",
        "\\J": "\\mathbf{J}",
        "\\bmu": "\\boldsymbol{\\mu}",
        "\\T": "^{\\top}",
        "\\inv": "^{-1}",
        "\\normal": "\\mathcal{N}",
        "\\argmin": "\\underset{#1}{\\operatorname{argmin}}",
        "\\argmax": "\\underset{#1}{\\operatorname{argmax}}",
      }
    });
  });
</script>

    </footer>

  </body>

  <script>

  function isAuto() {
    return document.body.classList.contains("auto");
  }

  function setTheme() {
    if (!isAuto()) {
      return
    }

    document.body.classList.remove("auto");
    let cls = "light";
    if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
      cls = "dark";
    }

    document.body.classList.add(cls);
  }

  function invertBody() {
    document.body.classList.toggle("dark");
    document.body.classList.toggle("light");
  }

  if (isAuto()) {
    window.matchMedia('(prefers-color-scheme: dark)').addListener(invertBody);
  }

  setTheme();

</script>


<script>
  
  function updateFigureNumbers() {

      const figRefs = document.querySelectorAll('.fig-ref');
      figRefs.forEach(ref => {
          const figId = ref.getAttribute('href').slice(1);
          const figElement = document.getElementById(figId);
          if (figElement) {
              const figIndex = Array.from(figures).indexOf(figElement) + 1;
              ref.textContent = `Figure ${figIndex}`;
          }
      });
  }

  
  window.addEventListener('load', updateFigureNumbers);
</script>



</html>